{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "\n",
    "# class PostureFeatureExtractor:\n",
    "def extract_features(keypoints):\n",
    "    \"\"\"\n",
    "    Extract features from 3D keypoints, adding a vertical nose offset feature\n",
    "    to help distinguish backward vs. normal posture.\n",
    "\n",
    "    Args:\n",
    "        keypoints (np.array): shape (17, 3), each row is (x, y, z)\n",
    "\n",
    "    Returns:\n",
    "        np.array: Extracted features (including vertical_nose_offset)\n",
    "    \"\"\"\n",
    "    # Indices (assuming COCO-style or similar)\n",
    "    nose = keypoints[0]            # (x, y, z)\n",
    "    left_shoulder = keypoints[11]  # (x, y, z)\n",
    "    right_shoulder = keypoints[12] # (x, y, z)\n",
    "    if np.isnan(nose).any():\n",
    "        return np.full((8,), np.nan)\n",
    "\n",
    "    # 1. Shoulder line & length\n",
    "    shoulder_vector = right_shoulder - left_shoulder\n",
    "    shoulder_length = np.linalg.norm(shoulder_vector)\n",
    "\n",
    "    # Horizontal angle (projection onto the XY plane)\n",
    "    horizontal_angle = np.arctan2(shoulder_vector[1], shoulder_vector[0])\n",
    "\n",
    "    # Vertical angle (projection onto the XZ plane)\n",
    "    vertical_angle = np.arctan2(\n",
    "        shoulder_vector[2],\n",
    "        np.sqrt(shoulder_vector[0]**2 + shoulder_vector[1]**2)\n",
    "    )\n",
    "\n",
    "    # Depth angle (projection onto the YZ plane)\n",
    "    depth_angle = np.arctan2(\n",
    "        shoulder_vector[2],\n",
    "        np.sqrt(shoulder_vector[0]**2 + shoulder_vector[1]**2 + shoulder_vector[2]**2)\n",
    "    )\n",
    "\n",
    "    # 3. Nose deviation from shoulder line (existing feature)\n",
    "    if shoulder_length != 0:\n",
    "        shoulder_unit_vector = shoulder_vector / shoulder_length\n",
    "    else:\n",
    "        shoulder_unit_vector = np.array([0, 0, 0])  # degenerate case\n",
    "\n",
    "    nose_projection = np.dot(nose - left_shoulder, shoulder_unit_vector)\n",
    "    nose_deviation = np.linalg.norm((nose - left_shoulder) - nose_projection * shoulder_unit_vector)\n",
    "\n",
    "    # 4. Z offset (if you already have it)\n",
    "    mid_shoulder = (left_shoulder + right_shoulder) / 2.0\n",
    "    z_offset = nose[2] - mid_shoulder[2]  # forward/back offset\n",
    "\n",
    "    # 5. **NEW** vertical offset (assuming y is vertical)\n",
    "\n",
    "    # Existing distance calculation\n",
    "    nose_distance = np.linalg.norm(nose - mid_shoulder)\n",
    "\n",
    "    nose_angle = calculate_angle_nose_shoulder_yaxis(nose, left_shoulder, right_shoulder)\n",
    "\n",
    "#         # Calculate shoulder width to use as a normalizing factor\n",
    "#         shoulder_width = np.linalg.norm(left_shoulder - right_shoulder)\n",
    "\n",
    "#         # Normalized nose distance\n",
    "#         normalized_nose_distance = nose_distance / shoulder_width if shoulder_width != 0 else 0\n",
    "\n",
    "    # Combine into a bigger feature vector\n",
    "    features = np.array([\n",
    "        shoulder_length,\n",
    "        horizontal_angle,\n",
    "        vertical_angle,\n",
    "        depth_angle,\n",
    "        nose_deviation,\n",
    "        z_offset,             # existing feature for forward/back separation\n",
    "        nose_distance,  # new feature for backward/normal separation\n",
    "        nose_angle\n",
    "    ])\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def calculate_angle_nose_shoulder_yaxis(nose_vector, left_shoulder, right_shoulder):\n",
    "    \"\"\"\n",
    "    Calculate the angle between the nose position and the shoulder midpoint relative to the y-axis.\n",
    "\n",
    "    Parameters:\n",
    "        nose_vector (numpy array): A vector [x, y, z] representing the nose position.\n",
    "        left_shoulder (numpy array): A vector [x, y, z] representing the left shoulder position.\n",
    "        right_shoulder (numpy array): A vector [x, y, z] representing the right shoulder position.\n",
    "\n",
    "    Returns:\n",
    "        float: The angle in radians between the nose and the shoulder midpoint relative to the y-axis.\n",
    "    \"\"\"\n",
    "    # Calculate the midpoint of the shoulders\n",
    "    shoulder_midpoint = (left_shoulder + right_shoulder) / 2.0\n",
    "\n",
    "    # Calculate the vector difference between the nose and shoulder midpoint\n",
    "    vector_diff = nose_vector - shoulder_midpoint\n",
    "\n",
    "    # Define the y-axis vector\n",
    "    y_axis_vector = np.array([0, 1, 0])\n",
    "\n",
    "    # Calculate the magnitudes of the vectors\n",
    "    mag_vector_diff = np.linalg.norm(vector_diff)\n",
    "    mag_y_axis = np.linalg.norm(y_axis_vector)\n",
    "\n",
    "    # Prevent division by zero\n",
    "    if mag_vector_diff == 0:\n",
    "        raise ValueError(\"Vector difference is zero, cannot compute angle.\")\n",
    "\n",
    "    # Calculate the dot product\n",
    "    dot_product = np.dot(vector_diff, y_axis_vector)\n",
    "\n",
    "    # Calculate the angle (in radians)\n",
    "    angle = np.arccos(dot_product / (mag_vector_diff * mag_y_axis))\n",
    "\n",
    "    return angle\n",
    "\n",
    "def prepare_dataset(results_normal, results_backwards, results_forwards):\n",
    "    \"\"\"\n",
    "    Prepare dataset from different posture types\n",
    "    Ignore samples where nose is NaN\n",
    "    \n",
    "    Args:\n",
    "        results_normal (np.array): Good posture keypoints\n",
    "        results_backwards (np.array): Bad posture - backwards\n",
    "        results_forwards (np.array): Bad posture - forwards\n",
    "    \n",
    "    Returns:\n",
    "        tuple: X (features), y (labels)\n",
    "    \"\"\"\n",
    "#     extractor = PostureFeatureExtractor()\n",
    "    \n",
    "    # Filter out samples where nose is NaN\n",
    "    normal_valid_indices = ~np.isnan(results_normal[:, 0]).any(axis=1)\n",
    "    backwards_valid_indices = ~np.isnan(results_backwards[:, 0]).any(axis=1)\n",
    "    forwards_valid_indices = ~np.isnan(results_forwards[:, 0]).any(axis=1)\n",
    "    \n",
    "    # Filter datasets\n",
    "    results_normal_filtered = results_normal[normal_valid_indices]\n",
    "    results_backwards_filtered = results_backwards[backwards_valid_indices]\n",
    "    results_forwards_filtered = results_forwards[forwards_valid_indices]\n",
    "    \n",
    "    # Print filtering information\n",
    "    print(f\"Normal samples: Total {len(results_normal)}, After filtering {len(results_normal_filtered)}\")\n",
    "    print(f\"Backwards samples: Total {len(results_backwards)}, After filtering {len(results_backwards_filtered)}\")\n",
    "    print(f\"Forwards samples: Total {len(results_forwards)}, After filtering {len(results_forwards_filtered)}\")\n",
    "    \n",
    "    # Extract features for filtered datasets\n",
    "    X_normal = np.array([extract_features(sample) for sample in results_normal_filtered])\n",
    "    X_backwards = np.array([extract_features(sample) for sample in results_backwards_filtered])\n",
    "    X_forwards = np.array([extract_features(sample) for sample in results_forwards_filtered])\n",
    "    \n",
    "    # Create labels\n",
    "    y_normal = np.zeros(len(X_normal))  # 0 for normal posture\n",
    "    y_backwards = np.ones(len(X_backwards))  # 1 for backwards posture\n",
    "    y_forwards = np.full(len(X_forwards), 2)  # 2 for forwards posture\n",
    "    \n",
    "    # Combine datasets\n",
    "    X = np.vstack((X_normal, X_backwards, X_forwards))\n",
    "    y = np.concatenate((y_normal, y_backwards, y_forwards))\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "def train_and_evaluate_model(X, y):\n",
    "    \"\"\"\n",
    "    Train and evaluate classification model\n",
    "    \n",
    "    Args:\n",
    "        X (np.array): Features\n",
    "        y (np.array): Labels\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Trained model, classification report\n",
    "    \"\"\"\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train SVM Classifier\n",
    "    classifier = SVC(kernel='rbf', random_state=42)\n",
    "    classifier.fit(X_train_scaled, y_train)\n",
    "    joblib.dump(classifier, '../model_checkpoint/svm_latest.joblib')\n",
    "\n",
    "    # Saving the scaler object to disk\n",
    "    with open('../model_checkpoint/scaler.pkl', 'wb') as file:\n",
    "        pickle.dump(scaler, file)\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    y_pred = classifier.predict(X_test_scaled)\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(y_test, y_pred, \n",
    "                                   target_names=['Normal', 'Backwards', 'Forwards'])\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Visualize confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', \n",
    "                xticklabels=['Normal', 'Backwards', 'Forwards'],\n",
    "                yticklabels=['Normal', 'Backwards', 'Forwards'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return classifier, report\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    # Load keypoints data\n",
    "    results_normal = np.load('../keypoints/normal_keypoints/keypoints_img_coord.npy')\n",
    "    results_backwards = np.load('../keypoints/backward_keypoints/keypoints_img_coord.npy')\n",
    "    results_forwards = np.load('../keypoints/forward_keypoints/keypoints_img_coord.npy')\n",
    "    \n",
    "    # Prepare dataset\n",
    "    X, y = prepare_dataset(results_normal, results_backwards, results_forwards)\n",
    "    \n",
    "    # Train and evaluate\n",
    "    classifier, report = train_and_evaluate_model(X, y)\n",
    "    \n",
    "    # Print classification report\n",
    "    print(report)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_features_pairplot(X, y):\n",
    "    \"\"\"\n",
    "    Create a pairplot of the 7 extracted features in X, colored by y.\n",
    "    X: shape (n_samples, 7)\n",
    "    y: shape (n_samples,)\n",
    "    \"\"\"\n",
    "#     Convert X,y to a pandas DataFrame for easy plotting\n",
    "    df = pd.DataFrame(X, columns=['ShoulderLength', 'ShoulderHorizAngle', \n",
    "                                  'ShoulderVertAngle', 'DepthAngle', 'NoseDeviation', 'Z offset', 'Nose Distance', 'Nose Angle'])\n",
    "    df['Label'] = y  # add labels as a column\n",
    "#     print(df)\n",
    "\n",
    "    # Create a pairplot, color-coded by 'Label'\n",
    "    sns.pairplot(\n",
    "        df, \n",
    "        hue='Label',\n",
    "        diag_kind='kde', \n",
    "        palette={0.0: 'blue', 1.0: 'green', 2.0: 'red'},\n",
    "        markers=['o', 's', '^'],  # circle, square, triangle\n",
    "        plot_kws={'alpha': 0.6, 's': 10}   # make points partially transparent\n",
    "    )\n",
    "#     g = sns.PairGrid(df, hue='Label', palette={0.0: 'blue', 1.0: 'green', 2.0: 'red'})\n",
    "#     g.map_diag(sns.kdeplot)\n",
    "#     g.map_offdiag(sns.scatterplot, alpha=0.6)\n",
    "#     g.add_legend()\n",
    "#     g.map_upper(lambda x, y, **kwargs: sns.scatterplot(x, y, **kwargs, s=30))\n",
    "#     g.map_lower(lambda x, y, **kwargs: sns.scatterplot(x, y, **kwargs, s=30))\n",
    "    # Adjusting visibility per class in upper or lower triangle can be very revealing\n",
    "    plt.suptitle(\"Pairplot of 6 Features (ShoulderLength, ShoulderHorizAngle, ShoulderVertAngle, NoseDeviation, Z offset, NoseDistance)\",\n",
    "                 y=1.02)  # shift title up a bit\n",
    "    plt.show()\n",
    "\n",
    "# # After you prepare your dataset (X, y):\n",
    "X, y = prepare_dataset(results_normal, results_backwards, results_forwards)\n",
    "\n",
    "plot_features_pairplot(X, y)\n",
    "\n",
    "# Then proceed to train_and_evaluate_model(...)\n",
    "classifier, report = train_and_evaluate_model(X, y)\n",
    "# df = pd.DataFrame(X, columns=['ShoulderLength', 'ShoulderHorizAngle', \\\n",
    "#                               'ShoulderVertAngle', 'NoseDeviation', 'Z offset', 'Nose Distance'])\n",
    "\n",
    "# df['Label'] = y  # add labels as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X, y)\n",
    "importances = rf.feature_importances_\n",
    "feature_names = ['ShoulderLength', 'ShoulderHorizAngle', \n",
    "                                  'ShoulderVertAngle', 'DepthAngle', 'NoseDeviation', 'Z offset', 'Nose Distance', 'Nose Angle']\n",
    "plt.barh(feature_names, importances)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_features_pairplot(X, y):\n",
    "    \"\"\"\n",
    "    Create a pairplot of the 7 extracted features in X, colored by y.\n",
    "    X: shape (n_samples, 7)\n",
    "    y: shape (n_samples,)\n",
    "    \"\"\"\n",
    "#     Convert X,y to a pandas DataFrame for easy plotting\n",
    "    df = pd.DataFrame(X, columns=['ShoulderLength', 'ShoulderHorizAngle', \n",
    "                                   'Z offset', 'Nose Angle'])\n",
    "    df['Label'] = y  # add labels as a column\n",
    "#     print(df)\n",
    "\n",
    "    # Create a pairplot, color-coded by 'Label'\n",
    "    sns.pairplot(\n",
    "        df, \n",
    "        hue='Label',\n",
    "        diag_kind='kde', \n",
    "        palette={0.0: 'blue', 1.0: 'green', 2.0: 'red'},\n",
    "        markers=['o', 's', '^'],  # circle, square, triangle\n",
    "        plot_kws={'alpha': 0.6, 's': 10}   # make points partially transparent\n",
    "    )\n",
    "#     g = sns.PairGrid(df, hue='Label', palette={0.0: 'blue', 1.0: 'green', 2.0: 'red'})\n",
    "#     g.map_diag(sns.kdeplot)\n",
    "#     g.map_offdiag(sns.scatterplot, alpha=0.6)\n",
    "#     g.add_legend()\n",
    "#     g.map_upper(lambda x, y, **kwargs: sns.scatterplot(x, y, **kwargs, s=30))\n",
    "#     g.map_lower(lambda x, y, **kwargs: sns.scatterplot(x, y, **kwargs, s=30))\n",
    "    # Adjusting visibility per class in upper or lower triangle can be very revealing\n",
    "    plt.suptitle(\"Pairplot of 6 Features (ShoulderLength, ShoulderHorizAngle, ShoulderVertAngle, NoseDeviation, Z offset, NoseDistance)\",\n",
    "                 y=1.02)  # shift title up a bit\n",
    "    plt.show()\n",
    "\n",
    "# # After you prepare your dataset (X, y):\n",
    "X, y = prepare_dataset(results_normal, results_backwards, results_forwards)\n",
    "\n",
    "plot_features_pairplot(X, y)\n",
    "\n",
    "# Then proceed to train_and_evaluate_model(...)\n",
    "classifier, report = train_and_evaluate_model(X, y)\n",
    "# df = pd.DataFrame(X, columns=['ShoulderLength', 'ShoulderHorizAngle', \\\n",
    "#                               'ShoulderVertAngle', 'NoseDeviation', 'Z offset', 'Nose Distance'])\n",
    "\n",
    "# df['Label'] = y  # add labels as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../AI System Data/Backwards/frames/\"\n",
    "image_files = [f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))][2000:2200]\n",
    "initialize_model()\n",
    "num = 0\n",
    "count = 0\n",
    "\n",
    "# Loading the scaler object from disk\n",
    "with open('../model_checkpoint/scaler.pkl', 'rb') as file:\n",
    "    loaded_scaler = pickle.load(file)\n",
    "\n",
    "# Assume X_new is your new data\n",
    "# X_new_scaled = loaded_scaler.transform(X_new)\n",
    "\n",
    "for i in np.arange(200):    \n",
    "\n",
    "    images = [Image.open(os.path.join(data_path, image_files[i]))]\n",
    "    keypoints = np.array(inference(images)[0])\n",
    "    features = extract_features(keypoints)\n",
    "    features_scaled  = loaded_scaler.transform(features.reshape(1, -1))\n",
    "#     print(features_scaled)\n",
    "    if not np.isnan(features_scaled).any():\n",
    "        if classifier.predict(features_scaled)[0] == 1:\n",
    "            count += 1\n",
    "        num += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
