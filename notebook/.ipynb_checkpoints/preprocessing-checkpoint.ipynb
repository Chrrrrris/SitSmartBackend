{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T02:39:44.918331Z",
     "start_time": "2024-12-06T02:39:44.910950Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "model = None\n",
    "\n",
    "\n",
    "def initialize_model():\n",
    "    global model\n",
    "    model =  mp_pose.Pose(\n",
    "    static_image_mode=True, min_detection_confidence=0.5, model_complexity=2)\n",
    "\n",
    "\n",
    "def inference(images, conf_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Perform inference on a batch of images using MediaPipe Pose to detect keypoints.\n",
    "\n",
    "    Args:\n",
    "        images (list): List of PIL.Image images.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of keypoints for each image. Each element is a list of tuples (x, y, z, visibility).\n",
    "              The order of keypoints matches the order of the input image list.\n",
    "    \"\"\"\n",
    "    global model\n",
    "    keypoints_list = []  # To store the keypoints for each image in the same order.\n",
    "\n",
    "    for idx, image in enumerate(images):\n",
    "        # Convert PIL.Image to numpy array and then to RGB for MediaPipe processing.\n",
    "        image_np = np.array(image)\n",
    "        image_rgb = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the image with MediaPipe Pose.\n",
    "        results = model.process(image_rgb)\n",
    "\n",
    "#         if results.pose_landmarks:\n",
    "#             # Extract keypoints as (x, y, z, visibility).\n",
    "#             keypoints = [\n",
    "#                 (landmark.x, landmark.y, landmark.z, landmark.visibility)\n",
    "#                 for landmark in results.pose_landmarks.landmark\n",
    "#             ]\n",
    "#             print('keypoints:', np.shape(keypoints))\n",
    "#         else:\n",
    "#             keypoints = []  # Empty list if no landmarks are detected.\n",
    "\n",
    "#         # Append keypoints to maintain order with images\n",
    "#         keypoints_list.append(keypoints)\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            keypoints = []\n",
    "            for landmark in results.pose_landmarks.landmark:\n",
    "                x = landmark.x if landmark.visibility > conf_threshold else np.nan\n",
    "                y = landmark.y if landmark.visibility > conf_threshold else np.nan\n",
    "                z = landmark.z if landmark.visibility > conf_threshold else np.nan\n",
    "\n",
    "                keypoints.append([x, y,z])\n",
    "\n",
    "            keypoints_list.append(keypoints)\n",
    "        else:\n",
    "            # Append an empty list if no keypoints are detected\n",
    "            keypoints_list.append(np.full((33, 3), np.nan))\n",
    "\n",
    "    return keypoints_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def readImages(interval, localStoragePath, userId):\n",
    "  pass\n",
    "\n",
    "def postureDetect(interval=60):\n",
    "  \"\"\"\n",
    "    Posture detection pipeline. This function reads images from the local storage, performs inference on them, and sends the results to the server.\n",
    "\n",
    "    Args:\n",
    "    - interval (int): Interval in seconds to read images from the local storage.\n",
    "\n",
    "    \"\"\"\n",
    "  results = inference(images)\n",
    "  return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../AI System Data/Lean Forward/frames\"\n",
    "image_files = [f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))]\n",
    "batch_size = 20\n",
    "counter = 0\n",
    "initialize_model()\n",
    "keypoints_list = []  # To store the keypoints for each image in the same order.\n",
    "conf_threshold=0.5\n",
    "images = [Image.open(os.path.join(data_path, image_file)) for image_file in image_files[0:batch_size]]\n",
    "for idx, image in enumerate(images):\n",
    "    # Convert PIL.Image to numpy array and then to RGB for MediaPipe processing.\n",
    "    image_np = np.array(image)\n",
    "    image_rgb = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image with MediaPipe Pose.\n",
    "    results = model.process(image_rgb)\n",
    "\n",
    "#         if results.pose_landmarks:\n",
    "#             # Extract keypoints as (x, y, z, visibility).\n",
    "#             keypoints = [\n",
    "#                 (landmark.x, landmark.y, landmark.z, landmark.visibility)\n",
    "#                 for landmark in results.pose_landmarks.landmark\n",
    "#             ]\n",
    "#             print('keypoints:', np.shape(keypoints))\n",
    "#         else:\n",
    "#             keypoints = []  # Empty list if no landmarks are detected.\n",
    "\n",
    "#         # Append keypoints to maintain order with images\n",
    "#         keypoints_list.append(keypoints)\n",
    "\n",
    "    if results.pose_world_landmarks:\n",
    "        keypoints = []\n",
    "        for landmark in results.pose_world_landmarks.landmark:\n",
    "            x = landmark.x if landmark.visibility > conf_threshold else np.nan\n",
    "            y = landmark.y if landmark.visibility > conf_threshold else np.nan\n",
    "            z = landmark.z if landmark.visibility > conf_threshold else np.nan\n",
    "\n",
    "            keypoints.append([x, y,z])\n",
    "\n",
    "        keypoints_list.append(keypoints)\n",
    "    else:\n",
    "        # Append an empty list if no keypoints are detected\n",
    "        keypoints_list.append(np.full((33, 3), np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints_list1  = keypoints_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints_list = np.array(keypoints_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints_list = np.array(keypoints_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(keypoints_list[6, : ,0], keypoints_list[6, : ,1])\n",
    "plt.scatter(keypoints_list[6, 0, 0], keypoints_list[6, 0, 1])\n",
    "plt.scatter(keypoints_list[6, 11, 0], keypoints_list[6, 11, 1])\n",
    "plt.scatter(keypoints_list[6, 12, 0], keypoints_list[6, 12, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# Example function to create a rotating 3D scatter plot for one frame\n",
    "def rotating_3d_frame(keypoints):\n",
    "    # Create a figure and a 3D axis\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Extract keypoints (assuming it's a 2D array of shape (33, 3))\n",
    "    keypoints = np.array(keypoints)\n",
    "    x, y, z = keypoints[:, 0], keypoints[:, 1], keypoints[:, 2]\n",
    "\n",
    "    # Plot the initial frame\n",
    "    scatter = ax.scatter(x, y, z, c='blue', label='Detected Keypoints')\n",
    "\n",
    "    # Mark missing points in red\n",
    "    missing = np.isnan(x)\n",
    "    ax.scatter(x[missing], y[missing], z[missing], c='red', label='Missing Keypoints')\n",
    "\n",
    "    # Add annotations for each keypoint index\n",
    "    for i, (xi, yi, zi) in enumerate(zip(x, y, z)):\n",
    "        if not np.isnan(xi):\n",
    "            ax.text(xi, yi, zi, str(i), fontsize=8)\n",
    "\n",
    "    # Set up the 3D plot\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "    ax.set_zlim(1, -1)\n",
    "    ax.set_title(\"Rotating 3D Pose\")\n",
    "    ax.legend()\n",
    "\n",
    "    # Update function for rotation\n",
    "    def update(frame):\n",
    "        ax.view_init(elev=30, azim=frame)  # Change azimuth angle\n",
    "        return scatter,\n",
    "\n",
    "    # Create the animation\n",
    "    ani = FuncAnimation(\n",
    "        fig,\n",
    "        update,\n",
    "        frames=range(0, 360, 2),  # Rotate full circle in steps\n",
    "        interval=50,  # Interval between frames in milliseconds\n",
    "        blit=False  # Turn off blitting for compatibility\n",
    "    )\n",
    "\n",
    "    # Show the animation\n",
    "    plt.show()\n",
    "#     ani.save(\"rotating_3d_frame.mp4\", writer=\"ffmpeg\", fps=30)\n",
    "\n",
    "    return ani\n",
    "\n",
    "# Example usage\n",
    "# Replace 'keypoints' with your actual data for one frame\n",
    "keypoints = keypoints_list[1]  # Simulate keypoints for demonstration\n",
    "from IPython.display import HTML\n",
    "\n",
    "ani = rotating_3d_frame(keypoints)  # Generate the animation\n",
    "HTML(ani.to_jshtml())  # Display the animation in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T06:05:37.445138Z",
     "start_time": "2024-12-06T05:37:07.179364Z"
    }
   },
   "outputs": [],
   "source": [
    "# Testing the function\n",
    "data_path = \"../../AI System Data/Lean Forward/frames\"\n",
    "image_files = [f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))]\n",
    "batch_size = 20\n",
    "counter = 0\n",
    "results_forward = []\n",
    "\n",
    "# Initialize the model\n",
    "initialize_model()\n",
    "\n",
    "for i in range(len(image_files) // batch_size):\n",
    "    # Load a batch of images\n",
    "    images = [Image.open(os.path.join(data_path, image_file)) for image_file in image_files[counter:counter + batch_size]]\n",
    "    \n",
    "    # Perform posture detection on the batch\n",
    "    batch_results = postureDetect(images)\n",
    "    \n",
    "    #Append batch results to the main results list\n",
    "    results_forward.extend(batch_results)\n",
    "\n",
    "    # Print keypoints results for the current batch\n",
    "    for idx, keypoints in enumerate(batch_results):\n",
    "        print(f\"Image {counter + idx}: Keypoints - {keypoints}\")\n",
    "    \n",
    "    counter += batch_size\n",
    "\n",
    "#Process remaining images\n",
    "images = [Image.open(os.path.join(data_path, image_file)) for image_file in image_files[counter:]]\n",
    "if images:\n",
    "    batch_results = postureDetect(images)\n",
    "    results_forward.extend(batch_results)\n",
    "\n",
    "    # Print keypoints for remaining images\n",
    "    for idx, keypoints in enumerate(batch_results):\n",
    "        print(f\"Image {counter + idx}: Keypoints - {keypoints}\")\n",
    "\n",
    "# Print final keypoints results\n",
    "for idx, keypoints in enumerate(results_forward):\n",
    "    print(f\"Image {idx}: Keypoints - {keypoints}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T01:35:29.333139Z",
     "start_time": "2024-12-12T01:35:28.920488Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def draw_keypoints_on_image(images, keypoints_list, index):\n",
    "    \"\"\"\n",
    "    Draws predicted keypoints on the image at the specified index.\n",
    "\n",
    "    Args:\n",
    "    - images (list): List of PIL Image objects.\n",
    "    - keypoints_list (list): List of keypoints for each image. Each element is a list of [x, y, z] keypoints.\n",
    "    - index (int): Index of the image to draw keypoints on.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    if index < 0 or index >= len(images):\n",
    "        print(\"Index out of range. Please provide a valid index.\")\n",
    "        return\n",
    "\n",
    "    image = np.array(images[index])  # Convert PIL Image to numpy array\n",
    "    keypoints = keypoints_list[index]\n",
    "\n",
    "    image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    for keypoint in keypoints:\n",
    "        x, y, z = keypoint\n",
    "        if x != 0 and y != 0:  # Skip if keypoint is [0, 0, 0]\n",
    "            cv2.circle(image_bgr, (int(x), int(y)), radius=5, color=(0, 255, 0), thickness=-1)\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Image at Index {index} with Keypoints\")\n",
    "    plt.show()\n",
    "\n",
    "draw_keypoints_on_image(images, results_forward[-11:], 1)  # Replace '5' with the desired index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T01:52:19.827227Z",
     "start_time": "2024-12-12T01:52:19.822093Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(f\"Keypoint {i} type: {type(results_forward[i])}\")\n",
    "    print(f\"Keypoint {i} shape/len: {np.shape(results_forward[i]) if isinstance(results_forward[i], np.ndarray) else len(results_forward[i])}\")\n",
    "    print(f\"Keypoint {i} data: {results_forward[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T01:53:25.047736Z",
     "start_time": "2024-12-12T01:53:24.596229Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_keypoints(results, save_path):\n",
    "    \"\"\"\n",
    "    Save keypoints results handling empty lists and 33x3 keypoints\n",
    "    \"\"\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    json_serializable_results = []\n",
    "\n",
    "    for keypoint in results:\n",
    "        if len(keypoint) == 0:\n",
    "            # Empty list of keypoints\n",
    "            json_serializable_results.append([])  \n",
    "        else:\n",
    "            # Convert NumPy array (if any) to Python list\n",
    "            # or assume keypoint is already a Python list of floats\n",
    "            # If it's guaranteed to be a NumPy array, you can do:\n",
    "            json_serializable_results.append(np.array(keypoint).tolist())\n",
    "\n",
    "            \n",
    "    # Save raw format as JSON\n",
    "    with open(os.path.join(save_path, 'keypoints_img_coord.json'), 'w') as f:\n",
    "         json.dump(json_serializable_results, f, indent=4)\n",
    "    \n",
    "    # Convert to numpy with consistent shape (N, 33, 3)\n",
    "    uniform_results = []\n",
    "    for keypoint in results:\n",
    "        if len(keypoint) == 0:  # Empty list\n",
    "            uniform_results.append(np.zeros((33, 3)))\n",
    "        else:\n",
    "            uniform_results.append(np.array(keypoint))\n",
    "    \n",
    "    keypoints_array = np.array(uniform_results)\n",
    "    np.save(os.path.join(save_path, 'keypoints_img_coord.npy'), keypoints_array)\n",
    "    \n",
    "    print(f\"Saved {len(results)} keypoints with shape {keypoints_array.shape}\")\n",
    "\n",
    "keypoints_path = \"../keypoints/\"\n",
    "# Usage in main code:\n",
    "save_path = os.path.join(keypoints_path, \"forward_keypoints\")\n",
    "save_keypoints(results_forward, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T02:48:01.691258Z",
     "start_time": "2024-12-12T01:59:11.611964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Testing the function\n",
    "data_path = \"../../AI System Data/Backwards/frames\"\n",
    "image_files = [f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))]\n",
    "batch_size = 20\n",
    "counter = 0\n",
    "results_backwards = []\n",
    "model = None\n",
    "# Initialize the model\n",
    "initialize_model()\n",
    "\n",
    "for i in range(len(image_files) // batch_size):\n",
    "    # Load a batch of images\n",
    "    images = [Image.open(os.path.join(data_path, image_file)) for image_file in image_files[counter:counter + batch_size]]\n",
    "    \n",
    "    # Perform posture detection on the batch\n",
    "    batch_results = postureDetect(images)\n",
    "    \n",
    "    # Append batch results to the main results list\n",
    "    results_backwards.extend(batch_results)\n",
    "\n",
    "    # Print keypoints results for the current batch\n",
    "    for idx, keypoints in enumerate(batch_results):\n",
    "        print(f\"Image {counter + idx}: Keypoints - {keypoints}\")\n",
    "    \n",
    "    counter += batch_size\n",
    "\n",
    "# Process remaining images\n",
    "images = [Image.open(os.path.join(data_path, image_file)) for image_file in image_files[counter:]]\n",
    "if images:\n",
    "    batch_results = postureDetect(images)\n",
    "    results_backwards.extend(batch_results)\n",
    "\n",
    "#     # Print keypoints for remaining images\n",
    "    for idx, keypoints in enumerate(batch_results):\n",
    "        print(f\"Image {counter + idx}: Keypoints - {keypoints}\")\n",
    "# \n",
    "# # Print final keypoints results\n",
    "# for idx, keypoints in enumerate(results_backwards):\n",
    "#     print(f\"Image {idx}: Keypoints - {keypoints}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T03:00:32.180557Z",
     "start_time": "2024-12-12T03:00:31.973292Z"
    }
   },
   "outputs": [],
   "source": [
    "draw_keypoints_on_image(images, results_backwards[-7:], 1)  # Replace '1' with the desired index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T03:00:48.410035Z",
     "start_time": "2024-12-12T03:00:48.028047Z"
    }
   },
   "outputs": [],
   "source": [
    "# Usage in main code:\n",
    "save_path = os.path.join(keypoints_path, \"backward_keypoints\")\n",
    "save_keypoints(results_backwards, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the function\n",
    "data_path = \"../../AI System Data/Normal posture/frames\"\n",
    "image_files = [f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))]\n",
    "batch_size = 20\n",
    "counter = 0\n",
    "results_normal_1 = []\n",
    "\n",
    "# Initialize the model\n",
    "initialize_model()\n",
    "images = [Image.open(os.path.join(data_path, image_file)) for image_file in image_files[0:0 + batch_size]]\n",
    "\n",
    "# Perform posture detection on the batch\n",
    "batch_results = postureDetect(images)\n",
    "\n",
    "# Append batch results to the main results list\n",
    "results_normal_1.extend(batch_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T03:59:44.776434Z",
     "start_time": "2024-12-12T03:01:16.833248Z"
    }
   },
   "outputs": [],
   "source": [
    "# Testing the function\n",
    "data_path = \"../../AI System Data/Normal posture/frames\"\n",
    "image_files = [f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))]\n",
    "batch_size = 20\n",
    "counter = 0\n",
    "results_normal = []\n",
    "\n",
    "# Initialize the model\n",
    "initialize_model()\n",
    "\n",
    "for i in range(len(image_files) // batch_size):\n",
    "    # Load a batch of images\n",
    "    images = [Image.open(os.path.join(data_path, image_file)) for image_file in image_files[counter:counter + batch_size]]\n",
    "    \n",
    "    # Perform posture detection on the batch\n",
    "    batch_results = postureDetect(images)\n",
    "    \n",
    "    # Append batch results to the main results list\n",
    "    results_normal.extend(batch_results)\n",
    "\n",
    "    # Print keypoints results for the current batch\n",
    "    # for idx, keypoints in enumerate(batch_results):\n",
    "    #     print(f\"Image {counter + idx}: Keypoints - {keypoints}\")\n",
    "    \n",
    "    counter += batch_size\n",
    "\n",
    "# Process remaining images\n",
    "images = [Image.open(os.path.join(data_path, image_file)) for image_file in image_files[counter:]]\n",
    "if images:\n",
    "    batch_results = postureDetect(images)\n",
    "    results_normal.extend(batch_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_normal = np.load('../keypoints/normal_keypoints/keypoints_img_coord.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_normal_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T04:07:38.410124Z",
     "start_time": "2024-12-12T04:07:38.272583Z"
    }
   },
   "outputs": [],
   "source": [
    "draw_keypoints_on_image(images, results_normal[-6:], 5)  # Replace '1' with the desired index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T04:08:05.131562Z",
     "start_time": "2024-12-12T04:08:04.550485Z"
    }
   },
   "outputs": [],
   "source": [
    "# keypoints_path = \"/Users/idrissunmola/Library/CloudStorage/OneDrive-JohnsHopkins/AI System Data/keypoints/\"\n",
    "# Usage in main code\n",
    "save_path = os.path.join(keypoints_path, \"normal_keypoints\")\n",
    "save_keypoints(results_normal, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# testing\n",
    "# local storage path\n",
    "data_path = \"../../AI System Data/Backwards/frames/\"\n",
    "# Get all files in the data_path folder\n",
    "image_files = [f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))]\n",
    "\n",
    "batch_size = 20\n",
    "counter = 0\n",
    "\n",
    "for i in tqdm(np.arange(1000)):    \n",
    "    \n",
    "    images = [Image.open(os.path.join(data_path, image_files[i]))]\n",
    "\n",
    "    if i == 0:\n",
    "        results_backwards = postureDetect(images)\n",
    "\n",
    "    else:\n",
    "        results_backwards = np.concatenate((results_backwards, postureDetect(images)), axis = 0)\n",
    "\n",
    "  # assert len(results) == len(images)\n",
    "\n",
    "# Print keypoints results\n",
    "for idx, keypoints in enumerate(results):\n",
    "    print(f\"Image {idx}: Keypoints - {keypoints}\")\n",
    "counter += batch_size\n",
    "\n",
    "# assert len(results) == len(images)\n",
    "\n",
    "# Print keypoints results\n",
    "for idx, keypoints in enumerate(results):\n",
    "    print(f\"Image {idx}: Keypoints - {keypoints}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('results_forwards.npy',results_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_backward = np.load('../../AI System Data/results_backwards.npy')\n",
    "results_normal = np.load('../../AI System Data/results_normal.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_forward = results_forward[:,:7, :]\n",
    "results_backward =  results_backward[:,:7, :]\n",
    "results_normal =  results_normal[:,:7, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(results_forward)):\n",
    "    results_forward[i,:,1] = results_forward[i,:, 1] - results_forward[i,0, 1]\n",
    "    results_forward[i,:,0] = results_forward[i,:, 0] - results_forward[i,0, 0]\n",
    "    results_backward[i,:,1] = results_backward[i,:, 1] - results_backward[i,0, 1]\n",
    "    results_backward[i,:,0] = results_backward[i,:, 0] - results_backward[i,0, 0]\n",
    "    results_normal[i,:,1] = results_normal[i,:, 1] - results_normal[i,0, 1]\n",
    "    results_normal[i,:,0] = results_normal[i,:, 0] - results_normal[i,0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    if int(image_files[i][-8:-4])<1269:\n",
    "        plt.scatter(results_forward[i, :, 0],results_forward[i, :, 1], s = 1)\n",
    "plt.xlim(0,1620)\n",
    "plt.ylim(1080,0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../AI System Data/Backwards/frames/\"\n",
    "# Get all files in the data_path folder\n",
    "image_files = [f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))]\n",
    "arr = []\n",
    "for i in range(1000):\n",
    "     if int(image_files[i][-8:-4])<1265:\n",
    "            arr.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    if 1269<=int(image_files[i][-8:-4])<3029:\n",
    "        plt.scatter(results_forward[i, :, 0],results_forward[i, :, 1], s = 1)\n",
    "plt.xlim(0,1620)\n",
    "plt.ylim(1080, 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    if 3029<=int(image_files[i][-8:-4])<5007:\n",
    "        plt.scatter(results_forward[i, :, 0],results_forward[i, :, 1], s = 1)\n",
    "plt.xlim(0,1620)\n",
    "plt.ylim(1080, 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    if int(image_files[i][-8:-4])>=5007:\n",
    "        plt.scatter(results_forward[i, :, 0],results_forward[i, :, 1], s = 1)\n",
    "plt.xlim(0,1620)\n",
    "plt.ylim(1080, 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    if int(image_files[i][-8:-4])<1269:\n",
    "        plt.scatter(results_forward[i, :, 0],results_forward[i, :, 1], s = 1)\n",
    "plt.xlim(0,1620)\n",
    "plt.ylim(1080, 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "#     if int(image_files[i][-8:-4])<1269:\n",
    "    if not 3029<=int(image_files[i][-8:-4])<5007:\n",
    "        plt.scatter(results_forward[i, :, 0],results_forward[i, :, 1], s = 1)\n",
    "# plt.xlim(0,1620)\n",
    "plt.ylim(1000, -1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_backward =  results_backward[:,:7, :]\n",
    "results_normal =  results_normal[:,:7, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(results_forward)):\n",
    "    results_backward[i,:,1] = results_backward[i,:, 1] - results_backward[i,0, 1]\n",
    "    results_backward[i,:,0] = results_backward[i,:, 0] - results_backward[i,0, 0]\n",
    "    results_normal[i,:,1] = results_normal[i,:, 1] - results_normal[i,0, 1]\n",
    "    results_normal[i,:,0] = results_normal[i,:, 0] - results_normal[i,0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "#     if int(image_files[i][-8:-4])<1269:\n",
    "    plt.scatter(results_backward[i, :, 0],results_backward[i, :, 1], s = 1)\n",
    "# plt.xlim(0,1620)\n",
    "plt.ylim(1000, -1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "#     if int(image_files[i][-8:-4])<1269:\n",
    "    plt.scatter(results_normal[i, :, 0],results_normal[i, :, 1], s = 1)\n",
    "# plt.xlim(0,1620)\n",
    "plt.ylim(1000, -1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "#     if int(image_files[i][-8:-4])<1269:\n",
    "    plt.scatter(results_normal[i, :, 0],results_normal[i, :, 1], s = 1, color = 'blue')\n",
    "    plt.scatter(results_backward[i, :, 0],results_backward[i, :, 1], s = 1, color = 'green')\n",
    "    if not 3029<=int(image_files[i][-8:-4])<5007:\n",
    "        plt.scatter(results_forward[i, :, 0],results_forward[i, :, 1], s = 1, color = 'red')\n",
    "        \n",
    "# plt.xlim(0,1620)\n",
    "plt.ylim(1000, -1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[1])\n",
    "plt.scatter(results[1,:,0], results[1, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[0])\n",
    "plt.scatter(results[0,:,0], results[0, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[1])\n",
    "plt.scatter(results[1,:,0], results[1, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def draw_keypoints_on_image(images, keypoints_list, index):\n",
    "    \"\"\"\n",
    "    Draws predicted keypoints on the image at the specified index.\n",
    "\n",
    "    Args:\n",
    "    - images (list): List of PIL Image objects.\n",
    "    - keypoints_list (list): List of keypoints for each image. Each element is a list of [x, y, z] keypoints.\n",
    "    - index (int): Index of the image to draw keypoints on.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    if index < 0 or index >= len(images):\n",
    "        print(\"Index out of range. Please provide a valid index.\")\n",
    "        return\n",
    "\n",
    "    image = np.array(images[index])  # Convert PIL Image to numpy array\n",
    "    keypoints = keypoints_list[index]\n",
    "\n",
    "    image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    for keypoint in keypoints:\n",
    "        x, y, z = keypoint\n",
    "        if not np.isnan(x):\n",
    "            if x != 0 and y != 0:  # Skip if keypoint is [0, 0, 0]\n",
    "                cv2.circle(image_bgr, (int(x)*image.shape[0], int(y)*image.shape[1]), radius=5, color=(0, 255, 0))\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Image at Index {index} with Keypoints\")\n",
    "    plt.show()\n",
    "image_path = '../../AI System Data/Backwards/frames/frame_00018.jpg'  # Example using the first image from normal posture\n",
    "images = [Image.open(image_path)]\n",
    "draw_keypoints_on_image(images, test, 0)  # Replace '5' with the desired index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([[[0.5417767763137817, 0.6495572328567505, -0.37978923320770264], [0.5579082369804382, 0.6103389263153076, -0.3343847990036011], [0.5699975490570068, 0.6098371744155884, -0.3346273899078369], [0.5814318656921387, 0.6123526692390442, -0.3344891667366028], [0.5220439434051514, 0.6139732003211975, -0.33176150918006897], [0.5098857283592224, 0.6155508160591125, -0.3320748507976532], [0.49869561195373535, 0.6192394495010376, -0.332326740026474], [0.6029415726661682, 0.6465146541595459, -0.13384835422039032], [0.48033618927001953, 0.6507847905158997, -0.12257558107376099], [0.567570686340332, 0.7185506820678711, -0.3066278100013733], [0.5137836337089539, 0.7239771485328674, -0.30566322803497314], [0.6650015115737915, 0.9262430667877197, -0.07647768408060074], [0.4184072017669678, 0.9364722967147827, -0.057871829718351364], [np.nan, np.nan, np.nan], [np.nan, np.nan, np.nan], [np.nan, np.nan, np.nan], [np.nan, np.nan, np.nan], [np.nan, np.nan, np.nan], [np.nan, np.nan, np.nan], [np.nan, np.nan, np.nan], [np.nan, np.nan, np.nan], [np.nan, np.nan, np.nan], [np.nan, np.nan, np.nan], [np.nan, np.nan, np.nan], [np.nan, np.nan, np.nan], [np.nan, np.nan, np.nan], [np.nan, np.nan, np.nan], [np.nan, np.nan, np.nan], [np.nan, np.nan, np.nan], [np.nan, np.nan, np.nan], [np.nan, np.nan, np.nan], [np.nan, np.nan, np.nan], [np.nan, np.nan, np.nan]]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(test[0,:,0]*images[0].size[0], test[0,:,1]*images[0].size[1])\n",
    "plt.imshow(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
